{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec05b836-2cc1-4fb3-a26f-1e1ef1d45119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import pyreadr\n",
    "import random\n",
    "from itertools import combinations\n",
    "from collections import OrderedDict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from einops import rearrange, repeat, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "from torchmetrics import Accuracy\n",
    "accuracy = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1135d6-49c2-464d-a2a9-a7ef39ac2d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b6cb3e4-b2a1-4ff3-9063-726bc4d5b515",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3999175d-2f5c-4954-b9e0-f03b906868be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setting\n",
    "DEVICE = 'cpu' # or 'cuda:0'\n",
    "\n",
    "exp_name = 'PXD002892'\n",
    "exp_cond = 'SEC2-heavy'\n",
    "cur_cv = 'cv1'\n",
    "feat_type = ['epf_200', 'seq_FCGR_16x']\n",
    "emb_size = [int(re.sub('x', '', i.split('_')[-1])) for i in feat_type]\n",
    "emb_size[1] = (emb_size[1])**2\n",
    "\n",
    "load_dir1 = '/'.join(['path to input', exp_name])\n",
    "load_dir2 = '/'.join(['path to EPF-data', exp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6f703-686f-4a93-8eaa-17570c36b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read data\n",
    "train_edge    = torch.tensor( np.load(load_dir1 + '/ref_edge_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "heldout_edge  = torch.tensor( np.load(load_dir1 + '/heldout_edge_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "delfold_edge  = torch.tensor( np.load(load_dir1 + '/delfold_edge_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "exp_edge      = torch.tensor( np.load(load_dir1 + '/exp_edge_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "train_label   = torch.tensor( np.load(load_dir1 + '/ref_label_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "heldout_label = torch.tensor( np.load(load_dir1 + '/heldout_label_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "delfold_label = torch.tensor( np.load(load_dir1 + '/delfold_label_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "train_mask    = torch.tensor( np.load(load_dir1 + '/train_mask_' + exp_cond + '.npz')['arr_0'][int(re.sub('cv', '', 'cv1'))-1] ).to(torch.bool).to(DEVICE)\n",
    "test_mask     = torch.tensor( np.load(load_dir1 + '/test_mask_' + exp_cond + '.npz')['arr_0'][int(re.sub('cv', '', 'cv1'))-1] ).to(torch.bool).to(DEVICE)\n",
    "\n",
    "print(train_edge.shape, heldout_edge.shape, delfold_edge.shape, exp_edge.shape)\n",
    "print(train_label.shape, heldout_label.shape, delfold_label.shape)\n",
    "print(train_mask.shape, test_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ce1b4a-97c6-4e48-a336-518c4b166c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4002, 55)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "torch.Size([4002, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "epf = list(pyreadr.read_r(load_dir2 + '/' + exp_cond + '.rds').values())[0].values\n",
    "pad = np.zeros((epf.shape[0], int(feat_type[0].split('_')[-1]) - epf.shape[1]))\n",
    "print(epf.shape)\n",
    "print(pad)\n",
    "\n",
    "epf = torch.tensor( np.concatenate([epf, pad], 1).reshape(-1, int(feat_type[0].split('_')[-1]), 1)).to(torch.float32).to(DEVICE)\n",
    "print(epf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a06e159-d6b2-4908-8946-4b5d913e0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3953]) torch.Size([49])\n",
      "torch.Size([3953, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "seq_in_exp_idx     = torch.tensor( np.load(load_dir1 + '/seq_in_exp_idx_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "seq_off_exp_idx    = torch.tensor( np.load(load_dir1 + '/seq_off_exp_idx_' + exp_cond + '.npz')['arr_0'] ).to(torch.long).to(DEVICE)\n",
    "seq                = torch.tensor( np.load(load_dir1 + '/feature_' + feat_type[1] + '_' + exp_cond + '.npz')['arr_0'] ).to(torch.float32)\n",
    "seq                = torch.unsqueeze(seq, -1).to(DEVICE)\n",
    "\n",
    "print(seq_in_exp_idx.shape, seq_off_exp_idx.shape)\n",
    "print(seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f89b41-8607-417a-8355-a271d96cdba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19440, 17750, 21667, 13327, 32241] 5645\n",
      "[0, 1, 3, 5, 6] 22581\n",
      "**************************************************\n",
      "tensor([False, False, False,  ..., False, False, False]) tensor(5645)\n",
      "**************************************************\n",
      "tensor([ True,  True, False,  ...,  True, False,  True]) tensor(22581)\n"
     ]
    }
   ],
   "source": [
    "#### Create val mask\n",
    "val_idx = random.sample((train_mask==1).nonzero().reshape(-1).tolist(), round(int((train_mask==1).sum())*0.2))\n",
    "train_idx = list(set((train_mask==1).nonzero().reshape(-1).tolist())^set(val_idx))\n",
    "print(val_idx[:5], len(val_idx))\n",
    "print(train_idx[:5], len(train_idx))\n",
    "print('*'*50)\n",
    "\n",
    "val_mask = torch.zeros(train_mask.shape[0])\n",
    "val_mask[val_idx] = 1\n",
    "val_mask = val_mask.bool()\n",
    "print(val_mask, val_mask.sum())\n",
    "print('*'*50)\n",
    "\n",
    "train_mask = torch.zeros(train_mask.shape[0])\n",
    "train_mask[train_idx] = 1\n",
    "train_mask = train_mask.bool()\n",
    "print(train_mask, train_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c0317-743f-4e8c-87f9-800c2c2780f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd641121-c319-436f-989d-878dac2aabbc",
   "metadata": {},
   "source": [
    "## Model layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0036ce4b-15b7-4914-85b9-5ef616a21fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding_layer(nn.Module):\n",
    "    def __init__(self, dim_1, dim_2):\n",
    "        super(embedding_layer, self).__init__()\n",
    "        self.Emb = nn.Embedding(dim_1, dim_2, max_norm=True)\n",
    "    \n",
    "    def forward(self, in_idx, off_idx, in_emb):\n",
    "        in_emb = in_emb.squeeze(-1)\n",
    "        all_tokens = len(list(set(in_idx.tolist() + off_idx.tolist())))\n",
    "        out_emb = self.Emb(torch.arange(all_tokens))\n",
    "        \n",
    "        past_off_idx = []\n",
    "        for idx in range(all_tokens):\n",
    "            if idx in in_idx:\n",
    "                out_emb[idx, :] += in_emb[(idx - len(past_off_idx)), ]\n",
    "            else:\n",
    "                past_off_idx.append(idx)\n",
    "        return out_emb.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4a7b9d-02a3-4ce6-b285-91c3f68c5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hid_dim=8, dropout=0.1, head_num=8, head_dim=32, max_size=emb_size*2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.conv = nn.Conv1d(1, hid_dim, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(max_size*(hid_dim + 1), 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, inp, e_idx, bias=None):\n",
    "        x = self.conv(inp.permute(0, 2, 1)).permute(0, 2, 1) + inp.repeat(1, 1, self.hid_dim)\n",
    "        \n",
    "        x_e1 = inp[e_idx[:, 0]] - inp[e_idx[:, 1]]\n",
    "        x_e2 = x[e_idx[:, 0]] - x[e_idx[:, 1]]\n",
    "        x_e = torch.cat((x_e1 , x_e2), -1).flatten(start_dim=1)\n",
    "        \n",
    "        x_e = F.dropout(F.relu(self.fc1(x_e)), p=self.dropout)\n",
    "        x_e = F.dropout(F.relu(self.fc2(x_e)), p=self.dropout)\n",
    "        w = torch.sigmoid(self.fc3(x_e)).squeeze()\n",
    "        feat = x.flatten(start_dim=1)\n",
    "        \n",
    "        if bias != None:\n",
    "            feat += bias\n",
    "        \n",
    "        return feat, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb1dae6-983c-481b-a395-822eaed81be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoderr(nn.Module):\n",
    "    def __init__(self, hid_dim=16, max_size=emb_size, dropout=0.1, all_tokens=20):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.emb = embedding_layer(all_tokens, emb_size[1])\n",
    "        self.enc = Encoder(hid_dim=hid_dim, max_size=sum(max_size), dropout=dropout)\n",
    "        \n",
    "    def forward(self, inp_e, inp_s, e_idx, in_list=None, off_list=None):\n",
    "        \n",
    "        if off_list is not None:\n",
    "            inp_s = self.emb(in_list, off_list, inp_s)\n",
    "        \n",
    "        inp = torch.cat([inp_e, inp_s], 1)\n",
    "        x, weight = self.enc(inp, e_idx, bias=None)\n",
    "        \n",
    "        return x, weight, inp[:, inp_e.shape[1]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a3b3b-0884-43bf-90e6-a5224c906f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcfd4882-2a38-46f2-8667-dacfc9e61bd9",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a3babe8-b36f-4e31-96ea-c45d50128845",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_weight    = 2.5\n",
    "L2_weight         = 0.25\n",
    "weight_decay      = 2.0e-3\n",
    "\n",
    "model = Encoderr(hid_dim=16, max_size=emb_size, dropout=0.3, all_tokens=max(seq_in_exp_idx.tolist() + seq_off_exp_idx.tolist()) + 1).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2b7fec-51d4-42fa-8c6b-6a1f6e239319",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = './performance_record'\n",
    "if not os.path.exists(out_path):\n",
    "      os.makedirs(out_path)\n",
    "\n",
    "out_path = './best_model_weight'\n",
    "if not os.path.exists(out_path):\n",
    "      os.makedirs(out_path)\n",
    "\n",
    "out_path = './output'\n",
    "if not os.path.exists(out_path):\n",
    "      os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cbaee-2da7-4123-99e8-8ec7bc29c208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_list = open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'train_loss_list']),'w')\n",
    "val_loss_list = open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'val_loss_list']),'w')\n",
    "train_acc_list = open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'train_acc_list']),'w')\n",
    "val_acc_list = open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'val_acc_list']),'w')\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #### Train =============================================================================================================================\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    _, train_label_predict, _ = model(epf, seq, train_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "    \n",
    "    train_loss = F.binary_cross_entropy(train_label_predict[train_mask], train_label[train_mask].to(torch.float32))\n",
    "    L2_loss = sum([ (v**2).sum()/2 for v in model.parameters() ])\n",
    "    \n",
    "    loss = predict_weight*train_loss + weight_decay*L2_weight*L2_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_acc = accuracy(train_label_predict[train_mask] > 0.5, train_label[train_mask] > 0.5)\n",
    "    \n",
    "    #### Validataion =============================================================================================================================\n",
    "    model.eval()\n",
    "    _, train_label_predict, _ = model(epf, seq, train_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "    \n",
    "    val_loss = F.binary_cross_entropy(train_label_predict[val_mask], train_label[val_mask].to(torch.float32))\n",
    "    val_acc = accuracy(train_label_predict[val_mask] > 0.5, train_label[val_mask] > 0.5)\n",
    "    \n",
    "    train_loss_list.write(str(train_loss.item()))\n",
    "    val_loss_list.write(str(val_loss.item()))\n",
    "    train_acc_list.write(str(train_acc.item()))\n",
    "    val_acc_list.write(str(val_acc.item()))\n",
    "    \n",
    "    train_loss_list.write('\\n')\n",
    "    val_loss_list.write('\\n')\n",
    "    train_acc_list.write('\\n')\n",
    "    val_acc_list.write('\\n')\n",
    "    \n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"all_loss=\", \"{:.4f}\".format(loss))\n",
    "    print(\"train_loss=\", \"{:.4f}\".format(predict_weight*train_loss), \"val_loss=\", \"{:.4f}\".format(predict_weight*val_loss),\n",
    "          \"lossL2=\", \"{:.4f}\".format(weight_decay*L2_weight*L2_loss),\n",
    "          \"train_acc=\", \"{:.4f}\".format(train_acc), \"val_acc=\", \"{:.4f}\".format(val_acc))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), './best_model_weight/' + '_'.join([exp_cond, cur_cv, 'stat_dict']))\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "train_loss_list.close()\n",
    "val_loss_list.close()\n",
    "train_acc_list.close()\n",
    "val_acc_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a4c99-f45e-4e34-9021-384de2caafc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ca03d24-fc9f-4754-8003-fe381ffca598",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4781fe-475c-44d0-bf67-a93b123cc98f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoderr(\n",
       "  (emb): embedding_layer(\n",
       "    (Emb): Embedding(2019, 256, max_norm=True)\n",
       "  )\n",
       "  (enc): Encoder(\n",
       "    (conv): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (fc1): Linear(in_features=7752, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load('./best_model_weight/' + '_'.join([exp_cond, cur_cv, 'stat_dict']))\n",
    "model_load = Encoderr(hid_dim=16, max_size=emb_size, dropout=0.3, all_tokens=max(seq_in_exp_idx.tolist() + seq_off_exp_idx.tolist()) + 1).to(DEVICE)\n",
    "model_load.load_state_dict(model_dict)\n",
    "model_load.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b84c74-9214-44f0-bec1-014195530725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train edge\n",
    "_, train_pred, _ = model_load(epf, seq, train_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "print((train_pred > 0.5).sum())\n",
    "print((train_pred > 0.5).sum() / train_pred.shape[0])\n",
    "print('*'*25)\n",
    "\n",
    "print( (((train_pred > 0.5).to(torch.float32) + (train_label > 0.5).to(torch.float32))==2).sum() / (train_label > 0.5).sum() )\n",
    "print( (((train_pred <= 0.5).to(torch.float32) + (train_label <= 0.5).to(torch.float32))==2).sum() / (train_label <= 0.5).sum() )\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'train', 'out']), train_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c53ad7-bc2d-4bfe-9123-7d36a2677f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = F.binary_cross_entropy(train_pred[train_mask], train_label[train_mask].to(torch.float32))\n",
    "val_loss = F.binary_cross_entropy(train_pred[val_mask], train_label[val_mask].to(torch.float32))\n",
    "test_loss = F.binary_cross_entropy(train_pred[test_mask], train_label[test_mask].to(torch.float32))\n",
    "train_acc = accuracy(train_pred[train_mask] > 0.5, train_label[train_mask] > 0.5)\n",
    "val_acc = accuracy(train_pred[val_mask] > 0.5, train_label[val_mask] > 0.5)\n",
    "test_acc = accuracy(train_pred[test_mask] > 0.5, train_label[test_mask] > 0.5)\n",
    "print(train_loss, val_loss, test_loss)\n",
    "print(train_acc, val_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ade95-fa4a-48e4-8b47-6da94198d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### heldout edge\n",
    "_, test_pred, _ = model_load(epf, seq, heldout_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "print((test_pred > 0.5).sum())\n",
    "print((test_pred > 0.5).sum() / test_pred.shape[0])\n",
    "print('*'*25)\n",
    "\n",
    "print( (((test_pred > 0.5).to(torch.float32) + (heldout_label > 0.5).to(torch.float32))==2).sum() / (heldout_label > 0.5).sum() )\n",
    "print( (((test_pred <= 0.5).to(torch.float32) + (heldout_label <= 0.5).to(torch.float32))==2).sum() / (heldout_label <= 0.5).sum() )\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'heldout', 'out']), test_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf857c-3c22-4832-8639-0e3d45a2ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### delfold edge\n",
    "_, del_pred, _ = model_load(epf, seq, delfold_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "print((del_pred > 0.5).sum())\n",
    "print((del_pred > 0.5).sum() / del_pred.shape[0])\n",
    "print('*'*25)\n",
    "\n",
    "print( (del_pred > 0.5).sum() / delfold_label.shape[0] )\n",
    "print( (((del_pred <= 0.5).to(torch.float32) + (delfold_label <= 0.5).to(torch.float32))==2).sum() / delfold_label.shape[0] )\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'delfold', 'out']), del_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505bfc0-feb6-4a4c-875e-2dcd39989315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### exp edge\n",
    "_, exp_pred, _ = model_load(epf, seq, exp_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "print((exp_pred > 0.5).sum())\n",
    "print((exp_pred > 0.5).sum() / exp_pred.shape[0])\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'exp', 'out']), exp_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b490660-23f8-4b18-bfa9-5465375e8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Emb of all edge\n",
    "all_edge = torch.cat([train_edge, heldout_edge, delfold_edge, exp_edge], 0)\n",
    "print(all_edge.shape)\n",
    "\n",
    "emb, all_pred, emb_seq = model_load(epf, seq, all_edge, in_list=seq_in_exp_idx, off_list=seq_off_exp_idx)\n",
    "print((all_pred > 0.5).sum())\n",
    "print((all_pred > 0.5).sum() / all_pred.shape[0])\n",
    "print(emb.shape, emb_seq.shape)\n",
    "\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'all', 'out']), all_pred.detach().numpy())\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'all_emb', 'out']), emb.detach().numpy())\n",
    "np.savez('./output/' + '_'.join([exp_cond, cur_cv, 'seq_emb', 'out']), emb_seq.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7dc695-e261-4f6e-b004-ed83959e9e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c6345d7-8525-4167-99a7-22ef07ea70be",
   "metadata": {},
   "source": [
    "## Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c28fcf-3307-48b2-a402-f2ec7e65b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'train_loss_list'])) as f:\n",
    "    train_loss_list = [float(line.rstrip('\\n')) for line in f]\n",
    "with open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'val_loss_list'])) as f:\n",
    "    val_loss_list = [float(line.rstrip('\\n')) for line in f]\n",
    "with open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'train_acc_list'])) as f:\n",
    "    train_acc_list = [float(line.rstrip('\\n')) for line in f]\n",
    "with open('./performance_record/' + '_'.join([exp_cond, cur_cv, 'val_acc_list'])) as f:\n",
    "    val_acc_list = [float(line.rstrip('\\n')) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ec8f7-6eef-47d5-bb75-914427de8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "ax[0].plot(train_acc_list, 'b', label = 'train_acc')\n",
    "ax[0].plot(val_acc_list, 'y', label = 'val_acc')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_loss_list, 'b', label = 'train_loss')\n",
    "ax[1].plot(val_loss_list, 'y', label = 'val_loss')\n",
    "ax[1].legend()\n",
    "fig.suptitle(' '.join([org, exp_name, exp_cond, cur_cv]), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f58777-a727-4936-b033-5c2c17d46e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3439e-2ef5-49ed-a029-d24518cb786b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f447cd-ceb4-45e1-baf8-dfe04ee49d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e835ef-51ea-4891-b647-19a6459c7eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd0c8a-da82-485d-addd-c2dbe8e27b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
